# Sprint 53 - Discovery Intelligence Pipeline

**InÃ­cio:** 09/02/2026
**DuraÃ§Ã£o estimada:** 1.5-2 semanas
**DependÃªncias:** Sprint 52 (Pipeline v3) completa
**Status:** âœ… Completa

---

## Progresso

| Epic | Status | DescriÃ§Ã£o |
|------|--------|-----------|
| Epic 1: Modelo de Dados | âœ… FEITO | Tabela `conversation_insights` criada |
| Epic 2: ServiÃ§o de ExtraÃ§Ã£o | âœ… FEITO | `app/services/extraction/` com prompt LLM |
| Epic 3: Post-Processor | âœ… FEITO | `ExtractionProcessor` priority 35 |
| Epic 4: PersistÃªncia RAG | âœ… FEITO | IntegraÃ§Ã£o com `doctor_context` |
| Epic 5: Auto-CorreÃ§Ã£o Dados | âœ… FEITO | AtualizaÃ§Ã£o automÃ¡tica de clientes |
| Epic 6: Backfill HistÃ³rico | âœ… FEITO | `app/workers/backfill_extraction.py` |
| Epic 7: Campaign Insights View | âœ… FEITO | View materializada `campaign_insights` |
| Epic 8: Observabilidade | âœ… FEITO | Endpoint `/extraction/stats` |
| Epic 9: Testes | âœ… FEITO | 30 testes unitÃ¡rios passando |
| Epic 10: API/Endpoints | âœ… FEITO | `app/api/routes/extraction.py` |

---

## Objetivo EstratÃ©gico

Criar um **pipeline robusto de extraÃ§Ã£o automÃ¡tica de dados** que captura informaÃ§Ãµes estruturadas de TODA conversa, transformando campanhas de discovery em inteligÃªncia acionÃ¡vel.

### Por que agora?

Campanhas de discovery estÃ£o rodando, mas **ZERO dados estÃ£o sendo extraÃ­dos e salvos**:
- Ãšltimos 30 dias: apenas 13 memÃ³rias salvas de ~500 conversas
- Tool `salvar_memoria` existe mas Julia raramente usa
- Dados valiosos perdidos a cada conversa

**Sem isso, campanhas de discovery sÃ£o desperdÃ­cio de recursos.**

### BenefÃ­cios

| Antes | Depois |
|-------|--------|
| ~0.4 memÃ³rias/dia | ~50-100 memÃ³rias/dia |
| 0% dados de campanha extraÃ­dos | 100% cobertura |
| CorreÃ§Ãµes de cadastro manuais | Auto-correÃ§Ã£o (confianÃ§a > 0.7) |
| Interesse nÃ£o rastreado | ClassificaÃ§Ã£o por turno |
| ObjeÃ§Ãµes perdidas | Catalogadas e agregadas |

---

## MotivaÃ§Ã£o (Problema Real: Campanha 19)

### AnÃ¡lise Concreta

Campanha 19 "Discovery Cardiologia" teve 50 envios e 16 respostas (32% response rate).

**Dados extraÃ­dos manualmente (nÃ£o salvos):**

| MÃ©dico | Interesse | Dado Revelado | Status DB |
|--------|-----------|---------------|-----------|
| Sergio | âœ… Positivo | "Trabalho no RJ" | RegiÃ£o nÃ£o atualizada |
| Enrico | âœ… Positivo | Mencionou Reumatologia | Cadastrado como Cirurgia Geral |
| Debora | âœ… Positivo | DisponÃ­vel fins de semana | NÃ£o registrado |
| Cristiano | âŒ Negativo | "JÃ¡ trabalho com empresas" | ObjeÃ§Ã£o nÃ£o catalogada |
| Danusa | âšª Neutro | "Talvez no futuro" | Follow-up nÃ£o agendado |
| Nadia | ğŸ¤– Bot | Sistema Gennex | Marcado manualmente |

**Problema:** Essas informaÃ§Ãµes foram perdidas. PrÃ³xima campanha nÃ£o terÃ¡ esse contexto.

---

## Arquitetura

### Fluxo de Dados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CONVERSATION TURN                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. MÃ©dico envia mensagem                                            â”‚
â”‚ 2. Pipeline processa (pre-processors â†’ LLM â†’ post-processors)       â”‚
â”‚ 3. Julia responde                                                    â”‚
â”‚ 4. SendMessageProcessor envia (priority 20)                         â”‚
â”‚ 5. SaveInteractionProcessor salva (priority 30)                     â”‚
â”‚ 6. â˜… ExtractionProcessor extrai dados (priority 35) â˜…               â”‚
â”‚ 7. MetricsProcessor finaliza (priority 40)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   EXTRACTION SERVICE                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:                                                               â”‚
â”‚   - mensagem_medico: str                                            â”‚
â”‚   - resposta_julia: str                                             â”‚
â”‚   - contexto: {nome, especialidade, campanha, histÃ³rico}            â”‚
â”‚                                                                      â”‚
â”‚ Output (JSON estruturado):                                          â”‚
â”‚   - interesse: positivo | negativo | neutro | incerto               â”‚
â”‚   - interesse_score: 0.0-1.0                                        â”‚
â”‚   - especialidade_mencionada: str | null                            â”‚
â”‚   - regiao_mencionada: str | null                                   â”‚
â”‚   - disponibilidade: str | null                                     â”‚
â”‚   - objecao: {tipo, descricao, severidade} | null                   â”‚
â”‚   - preferencias: list[str]                                         â”‚
â”‚   - restricoes: list[str]                                           â”‚
â”‚   - dados_corrigidos: {campo: valor_novo}                           â”‚
â”‚   - proximo_passo: enum                                             â”‚
â”‚   - confianca: 0.0-1.0                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DATA PERSISTENCE                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ conversation_insightsâ”‚  â”‚   doctor_context     â”‚                 â”‚
â”‚  â”‚ (nova tabela)        â”‚  â”‚   (existente - RAG)  â”‚                 â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚  â”‚ - interesse          â”‚  â”‚ - preferencias       â”‚                 â”‚
â”‚  â”‚ - objecoes           â”‚  â”‚ - restricoes         â”‚                 â”‚
â”‚  â”‚ - proximo_passo      â”‚  â”‚ - info_pessoal       â”‚                 â”‚
â”‚  â”‚ - dados_brutos       â”‚  â”‚ - embeddings         â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚              â”‚                        â”‚                              â”‚
â”‚              â”‚                        â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  campaign_insights    â”‚  â”‚      clientes       â”‚                 â”‚
â”‚  â”‚  (view materializada) â”‚  â”‚  (atualiza dados)   â”‚                 â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚  â”‚ - taxa_interesse      â”‚  â”‚ - especialidade     â”‚                 â”‚
â”‚  â”‚ - objecoes_comuns     â”‚  â”‚ - regiao            â”‚                 â”‚
â”‚  â”‚ - medicos_prontos     â”‚  â”‚ - preferencias_json â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### IntegraÃ§Ã£o com Pipeline Existente

```python
# app/pipeline/post_processors.py - ATUAL
class ValidateOutputProcessor:   priority = 5
class TimingProcessor:           priority = 10
class SendMessageProcessor:      priority = 20
class ChatwootResponseProcessor: priority = 25
class SaveInteractionProcessor:  priority = 30
# â˜… ExtractionProcessor:         priority = 35 â˜…  <- NOVO
class MetricsProcessor:          priority = 40
```

---

## Ã‰picos

### Epic 1: Modelo de Dados (P0 - CrÃ­tico) âœ… CONCLUÃDO

**Objetivo:** Criar estrutura de dados para armazenar extraÃ§Ãµes.

**MigraÃ§Ã£o aplicada:** `create_conversation_insights`

**Schema criado:**

```sql
CREATE TABLE conversation_insights (
    id BIGSERIAL PRIMARY KEY,
    conversation_id UUID NOT NULL REFERENCES conversations(id),
    interaction_id BIGINT REFERENCES interacoes(id),
    campaign_id BIGINT REFERENCES campanhas(id),
    cliente_id UUID NOT NULL REFERENCES clientes(id),
    interesse TEXT CHECK (interesse IN ('positivo', 'negativo', 'neutro', 'incerto')),
    interesse_score DECIMAL(3,2),
    especialidade_mencionada TEXT,
    regiao_mencionada TEXT,
    disponibilidade_mencionada TEXT,
    objecao_tipo TEXT,
    objecao_descricao TEXT,
    objecao_severidade TEXT,
    preferencias JSONB DEFAULT '[]',
    restricoes JSONB DEFAULT '[]',
    dados_corrigidos JSONB DEFAULT '{}',
    proximo_passo TEXT,
    modelo_extracao TEXT DEFAULT 'haiku',
    confianca DECIMAL(3,2),
    tokens_input INTEGER,
    tokens_output INTEGER,
    latencia_ms INTEGER,
    raw_extraction JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

**Ãndices criados:**
- `idx_insights_conversation`
- `idx_insights_campaign`
- `idx_insights_cliente`
- `idx_insights_interesse`
- `idx_insights_created`
- `idx_insights_proximo_passo`
- `idx_insights_objecao`
- `idx_insights_campaign_interesse`

---

### Epic 2: ServiÃ§o de ExtraÃ§Ã£o LLM (P0 - CrÃ­tico)

**Objetivo:** Criar serviÃ§o que usa Claude Haiku para extrair dados estruturados.

**Arquivos:**
- `app/services/extraction/extractor.py` (NOVO)
- `app/services/extraction/schemas.py` (NOVO)
- `app/services/extraction/prompts.py` (NOVO)
- `app/services/extraction/__init__.py` (NOVO)

**Tarefas:**
- [ ] 2.1 Criar estrutura de diretÃ³rio `app/services/extraction/`
- [ ] 2.2 Definir dataclass `ExtractionResult` com todos os campos
- [ ] 2.3 Definir dataclass `ExtractionContext` para input
- [ ] 2.4 Criar prompt otimizado para extraÃ§Ã£o
- [ ] 2.5 Implementar funÃ§Ã£o `extrair_dados_conversa()`
- [ ] 2.6 Adicionar parsing robusto de JSON (com fallback)
- [ ] 2.7 Adicionar retry com exponential backoff
- [ ] 2.8 Adicionar cache Redis (24h TTL por hash da mensagem)
- [ ] 2.9 Adicionar mÃ©tricas (tokens, latÃªncia, erros)
- [ ] 2.10 Tratar edge cases (mensagens muito curtas, emojis only, etc.)

---

### Epic 3: Post-Processor de ExtraÃ§Ã£o (P0 - CrÃ­tico)

**Objetivo:** Integrar extraÃ§Ã£o no pipeline de mensagens.

**Arquivos:**
- `app/pipeline/processors/extraction.py` (NOVO)

**Tarefas:**
- [ ] 3.1 Criar `ExtractionProcessor` com priority 35
- [ ] 3.2 Implementar `should_run()` - sÃ³ roda se hÃ¡ mensagem e resposta
- [ ] 3.3 Implementar `process()` - extrai e persiste
- [ ] 3.4 Tornar fault-tolerant (erros nÃ£o bloqueiam pipeline)
- [ ] 3.5 Adicionar feature flag `EXTRACTION_ENABLED`
- [ ] 3.6 Executar em background (nÃ£o bloqueia resposta)
- [ ] 3.7 Registrar no pipeline
- [ ] 3.8 Adicionar logs estruturados

---

### Epic 4: PersistÃªncia RAG (P1)

**Objetivo:** Salvar memÃ³rias extraÃ­das no `doctor_context` para RAG.

**Arquivos:**
- `app/services/extraction/persistence.py` (NOVO)

**Tarefas:**
- [ ] 4.1 Implementar `salvar_insight()` - salva em conversation_insights
- [ ] 4.2 Implementar `salvar_memorias_extraidas()` - cria entradas em doctor_context
- [ ] 4.3 Gerar embeddings para preferÃªncias e restriÃ§Ãµes
- [ ] 4.4 Categorizar memÃ³rias corretamente (preferencia, restricao, info_pessoal)
- [ ] 4.5 Evitar duplicatas (verificar se memÃ³ria similar jÃ¡ existe)
- [ ] 4.6 Adicionar source "extraction" para rastreamento

---

### Epic 5: Auto-CorreÃ§Ã£o de Dados (P1)

**Objetivo:** Atualizar dados de clientes automaticamente quando confianÃ§a Ã© alta.

**Campos Permitidos:**

| Campo | Auto-Update | Justificativa |
|-------|-------------|---------------|
| especialidade | âœ… Sim | MÃ©dico sabe sua especialidade |
| cidade | âœ… Sim | MÃ©dico sabe onde atua |
| estado | âœ… Sim | MÃ©dico sabe onde atua |
| regiao | âœ… Sim | MÃ©dico sabe onde atua |
| telefone | âŒ NÃ£o | Risco de dados incorretos |
| email | âŒ NÃ£o | Risco de dados incorretos |
| crm | âŒ NÃ£o | ValidaÃ§Ã£o manual necessÃ¡ria |
| nome | âŒ NÃ£o | Risco de confusÃ£o |

---

### Epic 6: Backfill HistÃ³rico (P2)

**Objetivo:** Processar conversas dos Ãºltimos 30 dias para popular insights.

**Arquivos:**
- `app/workers/backfill_extraction.py` (NOVO)
- `app/api/routes/jobs.py` (adicionar endpoint)

---

### Epic 7: Campaign Insights View (P2)

**Objetivo:** Criar view materializada para analytics de campanha.

---

### Epic 8: Observabilidade (P2)

**Objetivo:** MÃ©tricas e alertas para o pipeline de extraÃ§Ã£o.

---

### Epic 9: Testes (P1)

**Objetivo:** Cobertura de testes para todo o sistema de extraÃ§Ã£o.

---

### Epic 10: API/Endpoints (P2)

**Objetivo:** Endpoints para acessar dados de extraÃ§Ã£o.

---

## Estimativas

| Epic | Complexidade | Tempo Estimado |
|------|--------------|----------------|
| Epic 1: Modelo de Dados | Baixa | 1 hora âœ… |
| Epic 2: ServiÃ§o de ExtraÃ§Ã£o | Alta | 3 horas |
| Epic 3: Post-Processor | MÃ©dia | 2 horas |
| Epic 4: PersistÃªncia RAG | MÃ©dia | 2 horas |
| Epic 5: Auto-CorreÃ§Ã£o | Baixa | 1 hora |
| Epic 6: Backfill HistÃ³rico | MÃ©dia | 2 horas |
| Epic 7: Campaign Insights View | Baixa | 1 hora |
| Epic 8: Observabilidade | MÃ©dia | 1.5 horas |
| Epic 9: Testes | MÃ©dia | 3 horas |
| Epic 10: API/Endpoints | MÃ©dia | 2 horas |
| **Total** | | **18.5 horas** |

---

## Custos Estimados

| OperaÃ§Ã£o | Custo/Unidade | Volume DiÃ¡rio | Custo/Dia |
|----------|---------------|---------------|-----------|
| ExtraÃ§Ã£o (Haiku) | ~$0.0001 | ~500 msgs | ~$0.05 |
| Embeddings (Voyage) | ~$0.00002 | ~100 memÃ³rias | ~$0.002 |
| **Total** | | | **~$0.05/dia** |

---

## Riscos e MitigaÃ§Ãµes

| Risco | Probabilidade | Impacto | MitigaÃ§Ã£o |
|-------|---------------|---------|-----------|
| LLM retorna JSON invÃ¡lido | MÃ©dia | MÃ©dio | Parser com fallback + retry |
| LatÃªncia adicional no pipeline | Baixa | MÃ©dio | ExecuÃ§Ã£o em background |
| Custo de tokens escala | Baixa | Baixo | Haiku Ã© $0.25/1M tokens |
| ExtraÃ§Ã£o falha silenciosamente | MÃ©dia | Baixo | Logs + mÃ©tricas + alertas |
| Dados incorretos atualizados | Baixa | Alto | Threshold de confianÃ§a 0.7 |

---

## Ordem de ImplementaÃ§Ã£o

### Fase 1: FundaÃ§Ã£o (Dia 1)
1. âœ… **Epic 1**: Criar tabela `conversation_insights`
2. **Epic 2**: Implementar serviÃ§o de extraÃ§Ã£o

### Fase 2: IntegraÃ§Ã£o (Dia 2)
3. **Epic 3**: Criar ExtractionProcessor
4. **Epic 4**: Implementar persistÃªncia RAG

### Fase 3: AutomaÃ§Ã£o (Dia 3)
5. **Epic 5**: Auto-correÃ§Ã£o de dados
6. **Epic 7**: Campaign insights view

### Fase 4: HistÃ³rico (Dia 4)
7. **Epic 6**: Backfill de Ãºltimos 30 dias

### Fase 5: Qualidade (Dia 5)
8. **Epic 8**: Observabilidade
9. **Epic 9**: Testes
10. **Epic 10**: Endpoints de API

---

## Escopo de Captura

### Todas as Conversas, NÃ£o Apenas Discovery

| Tipo de Conversa | Captura | Justificativa |
|------------------|---------|---------------|
| Discovery | âœ… Sim | Foco inicial, dados de prospecÃ§Ã£o |
| Oferta de Vaga | âœ… Sim | Interesse, objeÃ§Ãµes, preferÃªncias de vaga |
| Follow-up | âœ… Sim | MudanÃ§a de interesse, novas restriÃ§Ãµes |
| ReativaÃ§Ã£o | âœ… Sim | RazÃµes de inatividade, novo interesse |
| Inbound (mÃ©dico inicia) | âœ… Sim | Demanda espontÃ¢nea, preferÃªncias |
| ConfirmaÃ§Ã£o de PlantÃ£o | âœ… Sim | Feedback pÃ³s-plantÃ£o |
| Handoff para Humano | âœ… Sim | SituaÃ§Ãµes complexas, objeÃ§Ãµes graves |

---

## Definition of Done (Sprint)

### ObrigatÃ³rio (P0)
- [x] Tabela `conversation_insights` criada e funcionando
- [x] ServiÃ§o de extraÃ§Ã£o retornando dados vÃ¡lidos
- [x] ExtractionProcessor integrado no pipeline
- [x] PersistÃªncia em doctor_context funcionando
- [x] Feature flag `EXTRACTION_ENABLED` implementada
- [x] Testes unitÃ¡rios passando (30 testes)

### DesejÃ¡vel (P1)
- [x] Auto-correÃ§Ã£o de dados com threshold (0.7)
- [x] Backfill worker implementado
- [x] View `campaign_insights` criada

### Futuro (P2)
- [x] Endpoints de API documentados
- [x] Endpoint `/extraction/stats` para mÃ©tricas
- [ ] Alertas de cobertura (a implementar)

---

## MÃ©tricas de Sucesso

### Antes (atual)
- MemÃ³rias salvas/dia: ~0.4
- Dados de campanha extraÃ­dos: 0%
- CorreÃ§Ãµes de cadastro: manual
- ObjeÃ§Ãµes catalogadas: 0

### Depois (meta)
- MemÃ³rias salvas/dia: ~50-100
- Dados de campanha extraÃ­dos: 100%
- CorreÃ§Ãµes de cadastro: automÃ¡ticas (confianÃ§a > 0.7)
- ObjeÃ§Ãµes catalogadas: 100%
