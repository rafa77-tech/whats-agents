# E46.1 - Schema de Banco de Dados

## Resumo

Criar as tabelas e views materializadas necessarias para o modulo de Market Intelligence.

## Contexto

O pipeline de grupos ja popula as tabelas `grupos_whatsapp`, `mensagens_grupo`, `vagas_grupo` e `metricas_grupos_diarias`. Este epico cria estruturas adicionais para analytics.

## Escopo

### Incluido
- Tabela `market_intelligence_daily`
- View materializada `mv_grupos_ranking`
- View materializada `mv_pipeline_metrics`
- Indices otimizados
- Funcao de refresh

### Excluido
- Migracao de dados historicos (sera outro epico)
- Triggers automaticos (sera configurado no worker)

---

## Especificacao Tecnica

### 1. Tabela `market_intelligence_daily`

```sql
-- Arquivo: migrations/YYYYMMDDHHMMSS_create_market_intelligence_daily.sql

CREATE TABLE market_intelligence_daily (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  data DATE NOT NULL,

  -- Metricas de Volume
  grupos_ativos INTEGER NOT NULL DEFAULT 0,
  mensagens_total INTEGER NOT NULL DEFAULT 0,
  mensagens_com_oferta INTEGER NOT NULL DEFAULT 0,
  vagas_extraidas INTEGER NOT NULL DEFAULT 0,
  vagas_importadas INTEGER NOT NULL DEFAULT 0,
  vagas_duplicadas INTEGER NOT NULL DEFAULT 0,
  vagas_descartadas INTEGER NOT NULL DEFAULT 0,

  -- Taxas (calculadas, armazenadas para performance)
  taxa_deteccao_oferta NUMERIC(5,4), -- mensagens_com_oferta / mensagens_total
  taxa_extracao NUMERIC(5,4),        -- vagas_extraidas / mensagens_com_oferta
  taxa_importacao NUMERIC(5,4),      -- vagas_importadas / vagas_extraidas
  taxa_duplicatas NUMERIC(5,4),      -- vagas_duplicadas / vagas_extraidas

  -- Qualidade
  confianca_media_extracao NUMERIC(5,4),
  confianca_media_match NUMERIC(5,4),

  -- Valor
  valor_medio_plantao INTEGER,
  valor_mediano_plantao INTEGER,
  valor_minimo_plantao INTEGER,
  valor_maximo_plantao INTEGER,

  -- Metadata
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),

  -- Constraints
  CONSTRAINT market_intelligence_daily_data_unique UNIQUE (data),
  CONSTRAINT market_intelligence_daily_data_not_future CHECK (data <= CURRENT_DATE)
);

-- Indice para queries por periodo
CREATE INDEX idx_market_intelligence_daily_data
  ON market_intelligence_daily (data DESC);

-- Comentarios
COMMENT ON TABLE market_intelligence_daily IS 'Snapshot diario de metricas de market intelligence';
COMMENT ON COLUMN market_intelligence_daily.taxa_deteccao_oferta IS 'Percentual de mensagens classificadas como oferta';
COMMENT ON COLUMN market_intelligence_daily.taxa_extracao IS 'Percentual de ofertas que geraram vagas extraidas';
```

### 2. View Materializada `mv_grupos_ranking`

```sql
-- Arquivo: migrations/YYYYMMDDHHMMSS_create_mv_grupos_ranking.sql

CREATE MATERIALIZED VIEW mv_grupos_ranking AS
SELECT
  g.id AS grupo_id,
  g.nome AS grupo_nome,
  g.tipo AS grupo_tipo,
  g.regiao AS grupo_regiao,
  g.ativo AS grupo_ativo,

  -- Metricas de volume (ultimos 30 dias)
  COUNT(DISTINCT m.id) FILTER (
    WHERE m.created_at >= NOW() - INTERVAL '30 days'
  ) AS mensagens_30d,

  COUNT(DISTINCT m.id) FILTER (
    WHERE m.eh_oferta = true
    AND m.created_at >= NOW() - INTERVAL '30 days'
  ) AS ofertas_30d,

  COUNT(DISTINCT vg.id) FILTER (
    WHERE vg.created_at >= NOW() - INTERVAL '30 days'
  ) AS vagas_extraidas_30d,

  COUNT(DISTINCT vg.id) FILTER (
    WHERE vg.status = 'importada'
    AND vg.created_at >= NOW() - INTERVAL '30 days'
  ) AS vagas_importadas_30d,

  -- Qualidade
  AVG(vg.confianca_geral) FILTER (
    WHERE vg.created_at >= NOW() - INTERVAL '30 days'
  ) AS confianca_media_30d,

  -- Valor medio
  AVG(vg.valor) FILTER (
    WHERE vg.valor IS NOT NULL
    AND vg.valor > 0
    AND vg.created_at >= NOW() - INTERVAL '30 days'
  ) AS valor_medio_30d,

  -- Score calculado (0-100)
  LEAST(100, GREATEST(0,
    (COUNT(DISTINCT vg.id) FILTER (
      WHERE vg.status = 'importada'
      AND vg.created_at >= NOW() - INTERVAL '30 days'
    ) * 2) +
    (AVG(vg.confianca_geral) FILTER (
      WHERE vg.created_at >= NOW() - INTERVAL '30 days'
    ) * 50)
  ))::INTEGER AS score_qualidade,

  -- Ultima atividade
  MAX(m.created_at) AS ultima_mensagem_em,
  MAX(vg.created_at) AS ultima_vaga_em,

  -- Metadata
  NOW() AS calculated_at

FROM grupos_whatsapp g
LEFT JOIN mensagens_grupo m ON m.grupo_id = g.id
LEFT JOIN vagas_grupo vg ON vg.grupo_origem_id = g.id
GROUP BY g.id, g.nome, g.tipo, g.regiao, g.ativo;

-- Indice unico para refresh concorrente
CREATE UNIQUE INDEX idx_mv_grupos_ranking_grupo_id
  ON mv_grupos_ranking (grupo_id);

-- Indices para ordenacao
CREATE INDEX idx_mv_grupos_ranking_score
  ON mv_grupos_ranking (score_qualidade DESC);
CREATE INDEX idx_mv_grupos_ranking_vagas
  ON mv_grupos_ranking (vagas_importadas_30d DESC);

COMMENT ON MATERIALIZED VIEW mv_grupos_ranking IS 'Ranking de grupos por qualidade e volume - refresh diario';
```

### 3. View Materializada `mv_pipeline_metrics`

```sql
-- Arquivo: migrations/YYYYMMDDHHMMSS_create_mv_pipeline_metrics.sql

CREATE MATERIALIZED VIEW mv_pipeline_metrics AS
SELECT
  DATE(m.created_at) AS data,

  -- Etapa 1: Mensagens
  COUNT(DISTINCT m.id) AS mensagens_total,
  COUNT(DISTINCT m.id) FILTER (WHERE m.status = 'processada') AS mensagens_processadas,
  COUNT(DISTINCT m.id) FILTER (WHERE m.passou_heuristica = true) AS mensagens_passou_heuristica,
  COUNT(DISTINCT m.id) FILTER (WHERE m.eh_oferta = true) AS mensagens_eh_oferta,

  -- Etapa 2: Vagas Extraidas
  COUNT(DISTINCT vg.id) AS vagas_extraidas,
  COUNT(DISTINCT vg.id) FILTER (WHERE vg.dados_minimos_ok = true) AS vagas_dados_ok,
  COUNT(DISTINCT vg.id) FILTER (WHERE vg.eh_duplicada = true) AS vagas_duplicadas,

  -- Etapa 3: Vagas Importadas
  COUNT(DISTINCT vg.id) FILTER (WHERE vg.status = 'importada') AS vagas_importadas,
  COUNT(DISTINCT vg.id) FILTER (WHERE vg.status = 'revisao') AS vagas_revisao,
  COUNT(DISTINCT vg.id) FILTER (WHERE vg.status = 'descartada') AS vagas_descartadas,

  -- Confianca media por etapa
  AVG(m.confianca_classificacao) FILTER (WHERE m.eh_oferta = true) AS confianca_classificacao_media,
  AVG(vg.confianca_geral) AS confianca_extracao_media,

  NOW() AS calculated_at

FROM mensagens_grupo m
LEFT JOIN vagas_grupo vg ON vg.mensagem_id = m.id
WHERE m.created_at >= NOW() - INTERVAL '90 days'
GROUP BY DATE(m.created_at);

-- Indice unico para refresh concorrente
CREATE UNIQUE INDEX idx_mv_pipeline_metrics_data
  ON mv_pipeline_metrics (data);

COMMENT ON MATERIALIZED VIEW mv_pipeline_metrics IS 'Metricas do pipeline por dia - refresh diario';
```

### 4. Funcao de Refresh

```sql
-- Arquivo: migrations/YYYYMMDDHHMMSS_create_refresh_market_intelligence.sql

CREATE OR REPLACE FUNCTION refresh_market_intelligence_views()
RETURNS void
LANGUAGE plpgsql
AS $$
BEGIN
  -- Refresh com CONCURRENTLY para nao bloquear leituras
  REFRESH MATERIALIZED VIEW CONCURRENTLY mv_grupos_ranking;
  REFRESH MATERIALIZED VIEW CONCURRENTLY mv_pipeline_metrics;

  -- Log de execucao (opcional)
  RAISE NOTICE 'Market intelligence views refreshed at %', NOW();
END;
$$;

COMMENT ON FUNCTION refresh_market_intelligence_views IS 'Atualiza todas as views materializadas de market intelligence';
```

---

## Definition of Done (DoD)

### Checklist Obrigatorio

- [ ] Migration criada com nome correto (`YYYYMMDDHHMMSS_create_*.sql`)
- [ ] Migration aplicada em DEV sem erros
- [ ] Migration aplicada em PROD sem erros
- [ ] Tabela `market_intelligence_daily` existe e aceita inserts
- [ ] View `mv_grupos_ranking` existe e retorna dados
- [ ] View `mv_pipeline_metrics` existe e retorna dados
- [ ] Funcao `refresh_market_intelligence_views()` executa sem erros
- [ ] Todos os indices criados
- [ ] Todos os comentarios aplicados
- [ ] Rollback testado (down migration)

### Testes Obrigatorios

#### Teste 1: Estrutura da Tabela
```sql
-- Verificar que tabela existe com colunas corretas
SELECT column_name, data_type, is_nullable
FROM information_schema.columns
WHERE table_name = 'market_intelligence_daily'
ORDER BY ordinal_position;

-- Esperado: 18 colunas conforme especificacao
```

#### Teste 2: Constraints
```sql
-- Testar unique constraint
INSERT INTO market_intelligence_daily (data) VALUES ('2024-01-01');
INSERT INTO market_intelligence_daily (data) VALUES ('2024-01-01'); -- Deve falhar

-- Testar check constraint (data futura)
INSERT INTO market_intelligence_daily (data) VALUES ('2099-01-01'); -- Deve falhar
```

#### Teste 3: Views Materializadas
```sql
-- Verificar que views existem e retornam dados
SELECT COUNT(*) FROM mv_grupos_ranking;
SELECT COUNT(*) FROM mv_pipeline_metrics;

-- Verificar refresh funciona
SELECT refresh_market_intelligence_views();
```

#### Teste 4: Performance
```sql
-- Query deve executar em < 100ms
EXPLAIN ANALYZE
SELECT * FROM mv_grupos_ranking
ORDER BY score_qualidade DESC
LIMIT 20;
```

---

## Criterios de Aceitacao

| ID | Criterio | Verificacao |
|----|----------|-------------|
| AC1 | Tabela criada | `\d market_intelligence_daily` retorna schema |
| AC2 | Views criadas | `\dm` lista as 2 views materializadas |
| AC3 | Indices criados | `\di` lista todos os indices |
| AC4 | Constraints funcionam | Testes de constraint passam |
| AC5 | Refresh funciona | Funcao executa sem erro |
| AC6 | Performance OK | Query em < 100ms |

---

## Comandos de Execucao

```bash
# Aplicar migration em DEV
npx supabase db push --db-url $DEV_DATABASE_URL

# Aplicar migration em PROD (via MCP)
# Usar mcp__supabase__apply_migration

# Verificar aplicacao
npx supabase db diff

# Rollback se necessario
npx supabase db reset
```

---

## Notas para o Desenvolvedor

1. **Ordem de execucao**: Criar tabela primeiro, depois views, depois funcao
2. **CONCURRENTLY**: Requer indice UNIQUE na view para funcionar
3. **Performance**: Views materializadas sao snapshots, nao tempo real
4. **Refresh**: Sera chamado por worker diario (configurado em outro epico)

## Riscos

| Risco | Mitigacao |
|-------|-----------|
| Views demoram muito | Limitar periodo (90 dias) |
| Lock durante refresh | Usar CONCURRENTLY |
| Dados inconsistentes | Refresh em horario de baixo uso |
