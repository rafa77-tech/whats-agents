# Sprint 14: Scraping de Vagas de Grupos WhatsApp

## Objetivo

Implementar sistema de captura, classifica√ß√£o e extra√ß√£o de ofertas de plant√£o de grupos de WhatsApp, com deduplica√ß√£o inteligente e importa√ß√£o autom√°tica para o banco de vagas.

## Problema que Resolve

A Julia participa de ~300 grupos de WhatsApp onde s√£o postadas ofertas de plant√£o de diversas fontes (Revoluna e terceiros). Hoje essas mensagens s√£o ignoradas. Este sistema vai:

1. **Capturar** todas as mensagens de grupos
2. **Classificar** quais s√£o ofertas de plant√£o (vs conversas gerais)
3. **Extrair** dados estruturados (hospital, data, valor, etc)
4. **Normalizar** para entidades conhecidas (hospitais, especialidades)
5. **Deduplicar** vagas repetidas em m√∫ltiplos grupos
6. **Importar** automaticamente vagas de alta confian√ßa
7. **Rastrear** todas as fontes de cada vaga

## Contexto

| Aspecto | Valor |
|---------|-------|
| Grupos monitorados | ~300 |
| Volume estimado | 500-2000 msgs/dia |
| Fonte das vagas | Maioria terceiros |
| Formato das mensagens | Texto livre |
| Crit√©rio de dedup | Hospital + Data + Per√≠odo + Especialidade |
| Modo de importa√ß√£o | Autom√°tico com regras |
| Rastreamento | Completo (todas as fontes) |

## Decis√µes de Escopo

| Decis√£o | Escolha | Motivo |
|---------|---------|--------|
| **Imagens/prints** | Ignorar no MVP | Complexidade de OCR, foco em texto primeiro |
| **Vagas em lote** | Suportar | Uma mensagem pode conter 3-5 vagas, extrair todas |
| **Hospital desconhecido** | Criar novo + busca web | Enriquecer com dados da web (endere√ßo, cidade, etc) |
| **Vagas passadas** | Descartar | Se data < hoje, n√£o importar |
| **Mensagens editadas** | Ignorar edi√ß√µes | Processar apenas mensagem original |

## Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     WEBHOOK EVOLUTION API                        ‚îÇ
‚îÇ                  (j√° recebe msgs de grupo)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. INGESTAO (E01)                                              ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  ‚Ä¢ Salvar TODAS as mensagens de grupo em `mensagens_grupo`      ‚îÇ
‚îÇ  ‚Ä¢ Campos: grupo_jid, sender, texto, timestamp, status          ‚îÇ
‚îÇ  ‚Ä¢ Cadastro de grupos em `grupos_whatsapp`                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. CLASSIFICACAO (E02) - Filtro de 2 est√°gios                  ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  EST√ÅGIO 1: Regex/Heur√≠stica (custo zero)                       ‚îÇ
‚îÇ  ‚Ä¢ Descarta: "bom dia", "obrigado", √°udios, stickers            ‚îÇ
‚îÇ  ‚Ä¢ Passa: mensagens com keywords (plant√£o, vaga, R$, hospital)  ‚îÇ
‚îÇ  ‚Ä¢ Objetivo: eliminar ~70% do volume                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  EST√ÅGIO 2: LLM Haiku (custo baixo)                             ‚îÇ
‚îÇ  ‚Ä¢ Classifica: √© oferta de plant√£o? (sim/n√£o)                   ‚îÇ
‚îÇ  ‚Ä¢ S√≥ roda nos ~30% que passaram do est√°gio 1                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. EXTRACAO (E03) - Parsing estruturado                        ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  ‚Ä¢ LLM Haiku extrai campos:                                     ‚îÇ
‚îÇ    - hospital (texto bruto)                                     ‚îÇ
‚îÇ    - data (YYYY-MM-DD)                                          ‚îÇ
‚îÇ    - hor√°rio in√≠cio/fim                                         ‚îÇ
‚îÇ    - per√≠odo (manh√£/tarde/noturno/12h/24h)                      ‚îÇ
‚îÇ    - especialidade                                              ‚îÇ
‚îÇ    - valor (R$)                                                 ‚îÇ
‚îÇ    - contato (telefone/nome)                                    ‚îÇ
‚îÇ    - observa√ß√µes                                                ‚îÇ
‚îÇ  ‚Ä¢ Confian√ßa: score 0-1 em cada campo                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. NORMALIZACAO + MATCH (E04)                                  ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  ‚Ä¢ Hospital: fuzzy match com tabela `hospitais`                 ‚îÇ
‚îÇ    - "HSL ABC" ‚Üí Hospital S√£o Luiz ABC (85% match)              ‚îÇ
‚îÇ    - Se < 70%: candidato para revis√£o/cadastro                  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ Especialidade: match com `especialidades`                    ‚îÇ
‚îÇ  ‚Ä¢ Per√≠odo: normalizar para IDs existentes                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ Tabela `hospitais_alias` para aprender varia√ß√µes             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. DEDUPLICACAO (E05)                                          ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  ‚Ä¢ Chave: hash(hospital_id + data + periodo_id)                 ‚îÇ
‚îÇ  ‚Ä¢ Janela: 48h (mesma vaga vista em 48h = duplicada)            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ Se NOVA: insere em `vagas_grupo`                             ‚îÇ
‚îÇ  ‚Ä¢ Se DUPLICADA: atualiza contador, registra fonte              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚Ä¢ Rastreamento completo de todas as fontes                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  6. IMPORTACAO (E06)                                            ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  AUTOM√ÅTICA (regras):                                           ‚îÇ
‚îÇ  ‚Ä¢ Confian√ßa > 90% + hospital conhecido ‚Üí auto-importa          ‚îÇ
‚îÇ  ‚Ä¢ Confian√ßa 70-90% ‚Üí fila de revis√£o                           ‚îÇ
‚îÇ  ‚Ä¢ Confian√ßa < 70% ‚Üí descartada (log mantido)                   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  MANUAL (Slack):                                                ‚îÇ
‚îÇ  ‚Ä¢ Gestor pode revisar fila e aprovar/rejeitar                  ‚îÇ
‚îÇ  ‚Ä¢ "listar vagas pendentes" / "importar vaga X"                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## √âpicos

| √âpico | Nome | Stories | Estimativa | Descri√ß√£o |
|-------|------|---------|------------|-----------|
| E01 | Modelo de Dados | 10 | 7.25h | Schema, √≠ndices, RLS, seeds de alias |
| E02 | Ingest√£o de Mensagens | 7 | 7.25h | Captura e armazenamento de mensagens |
| E03 | Heur√≠stica de Classifica√ß√£o | 6 | 7.5h | Filtro r√°pido por keywords/regex |
| E04 | Classifica√ß√£o LLM | 5 | 8h | Classifica√ß√£o bin√°ria com Claude Haiku |
| E05 | Extra√ß√£o de Dados | 5 | 10h | Parsing estruturado (suporta m√∫ltiplas vagas) |
| E06 | Fuzzy Match de Entidades | 7 | 9.5h | Normaliza√ß√£o de hospital/especialidade |
| E07 | Cria√ß√£o de Hospital via Web | 6 | 8h | Auto-criar hospitais com busca web |
| E08 | Deduplica√ß√£o | 6 | 7h | Identificar vagas repetidas entre grupos |
| E09 | Importa√ß√£o Autom√°tica | 7 | 10h | Regras de confian√ßa e importa√ß√£o |
| E10 | Interface Slack | 9 | 13h | Tools para revis√£o e gest√£o manual |
| E11 | Worker e Orquestra√ß√£o | 8 | 13.5h | Pipeline ass√≠ncrono com retry |
| E12 | M√©tricas e Monitoramento | 8 | 12.5h | Dashboard, alertas, custos |

**Total:** 84 stories | **~113.5h** (~14 dias)

### Detalhamento dos √âpicos

**E01 - Modelo de Dados** ([epic-01-modelo-dados.md](epic-01-modelo-dados.md))
- Criar tabelas: `grupos_whatsapp`, `contatos_grupo`, `mensagens_grupo`, `vagas_grupo`
- Tabelas de rastreamento: `vagas_grupo_fontes`
- Tabelas de alias: `hospitais_alias`, `especialidades_alias`
- Fila de processamento: `fila_processamento_grupos`
- √çndices, triggers, RLS, seeds de alias comuns

**E02 - Ingest√£o de Mensagens** ([epic-02-ingestao-mensagens.md](epic-02-ingestao-mensagens.md))
- Salvar mensagens de grupo (n√£o mais ignorar)
- Criar/atualizar registros de grupos e contatos
- Integra√ß√£o com parser.py existente
- Enfileirar para processamento

**E03 - Heur√≠stica de Classifica√ß√£o** ([epic-03-heuristica-classificacao.md](epic-03-heuristica-classificacao.md))
- Keywords positivas: plant√£o, vaga, R$, hospitais
- Keywords negativas: bom dia, obrigado, perguntas
- Score de 0-1 baseado em matches
- Filtrar ~70% das mensagens (custo zero)

**E04 - Classifica√ß√£o LLM** ([epic-04-classificacao-llm.md](epic-04-classificacao-llm.md))
- Prompt bin√°rio: "√â oferta de plant√£o?"
- Claude Haiku para custo baixo
- Cache em Redis para mensagens repetidas
- S√≥ processa ~30% que passou da heur√≠stica

**E05 - Extra√ß√£o de Dados** ([epic-05-extracao-dados.md](epic-05-extracao-dados.md))
- Prompt de extra√ß√£o estruturada
- Suporte a m√∫ltiplas vagas por mensagem
- Valida√ß√£o de data (descarta passadas)
- Scores de confian√ßa por campo

**E06 - Fuzzy Match de Entidades** ([epic-06-fuzzy-match.md](epic-06-fuzzy-match.md))
- Busca em alias primeiro (match exato)
- pg_trgm para similaridade
- Normaliza√ß√£o de texto (acentos, lowercase)
- Match de per√≠odo, setor, tipo_vaga

**E07 - Cria√ß√£o de Hospital via Web** ([epic-07-criacao-hospital-web.md](epic-07-criacao-hospital-web.md))
- Se fuzzy match < 70%: buscar na web
- Extrair: nome oficial, endere√ßo, cidade
- Criar hospital + alias automaticamente
- Fallback para dados m√≠nimos

**E08 - Deduplica√ß√£o** ([epic-08-deduplicacao.md](epic-08-deduplicacao.md))
- Hash: hospital_id + data + per√≠odo + especialidade
- Janela temporal de 48h
- Rastreamento de m√∫ltiplas fontes
- Incremento de contador

**E09 - Importa√ß√£o Autom√°tica** ([epic-09-importacao-automatica.md](epic-09-importacao-automatica.md))
- Confian√ßa >= 90%: auto-importa
- Confian√ßa 70-90%: fila de revis√£o
- Confian√ßa < 70%: descarta
- C√°lculo de confian√ßa ponderado

**E10 - Interface Slack** ([epic-10-interface-slack.md](epic-10-interface-slack.md))
- Listar vagas para revis√£o
- Aprovar/rejeitar vagas
- Ver detalhes de vaga
- Estat√≠sticas de captura
- Gerenciar aliases de hospital

**E11 - Worker e Orquestra√ß√£o** ([epic-11-worker-orquestracao.md](epic-11-worker-orquestracao.md))
- Fila com retry e backoff exponencial
- Pipeline com 6 est√°gios
- Workers paralelos (semaphore)
- Health check e reprocessamento

**E12 - M√©tricas e Monitoramento** ([epic-12-metricas-monitoramento.md](epic-12-metricas-monitoramento.md))
- M√©tricas agregadas por dia/grupo
- Dashboard no Slack
- Alertas autom√°ticos (fila grande, erros, custo)
- Endpoint de m√©tricas API

## Modelo de Dados

### Depend√™ncias da Tabela `vagas`

A tabela `vagas` possui os seguintes campos obrigat√≥rios que precisamos preencher:

| Campo | Tabela FK | Obrigat√≥rio | Extra√ß√£o |
|-------|-----------|-------------|----------|
| `hospital_id` | `hospitais` | **SIM** | Fuzzy match do nome |
| `especialidade_id` | `especialidades` | **SIM** | Fuzzy match |
| `setor_id` | `setores` | N√£o | PA, RPA, Hospital, C. Cir√∫rgico, SADT |
| `periodo_id` | `periodos` | N√£o | Vespertino, Noturno, Diurno, Cinderela |
| `tipos_vaga_id` | `tipos_vaga` | N√£o | Cobertura, Fixo, Ambulatorial, Mensal |
| `forma_recebimento_id` | `formas_recebimento` | N√£o | PF, PJ, CLT, SCP |
| `data` | - | N√£o | Extrair da mensagem |
| `hora_inicio` | - | N√£o | Extrair da mensagem |
| `hora_fim` | - | N√£o | Extrair da mensagem |
| `valor` | - | N√£o | Extrair da mensagem |
| `observacoes` | - | N√£o | Texto adicional |

### Dados Cr√≠ticos a Capturar

1. **Origem (Grupo WhatsApp):** De qual grupo veio a oferta
2. **Respons√°vel (Quem postou):** Nome e telefone de quem publicou a vaga
3. **Hospital:** Nome do hospital/cl√≠nica
4. **Especialidade:** Qual especialidade m√©dica
5. **Data/Hor√°rio:** Quando √© o plant√£o
6. **Valor:** Quanto paga

### Novas Tabelas

```sql
-- Cadastro dos grupos monitorados
CREATE TABLE grupos_whatsapp (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    jid TEXT UNIQUE NOT NULL,              -- "123456@g.us"
    nome TEXT,
    descricao TEXT,
    tipo TEXT DEFAULT 'vagas',             -- "vagas", "geral", "regional"
    regiao TEXT,                           -- "ABC", "SP Capital", etc
    ativo BOOLEAN DEFAULT true,
    total_mensagens INTEGER DEFAULT 0,
    total_ofertas INTEGER DEFAULT 0,
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);

-- Contatos que postam vagas nos grupos (respons√°veis)
CREATE TABLE contatos_grupo (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    jid TEXT UNIQUE NOT NULL,              -- "5511999999999@s.whatsapp.net"
    telefone TEXT,                         -- "5511999999999"
    nome TEXT,                             -- Nome do pushName
    empresa TEXT,                          -- Se identific√°vel (outro staffing, hospital)
    total_vagas_postadas INTEGER DEFAULT 0,
    primeiro_contato TIMESTAMPTZ,
    ultimo_contato TIMESTAMPTZ,
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);

-- Todas as mensagens capturadas
CREATE TABLE mensagens_grupo (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    grupo_id UUID REFERENCES grupos_whatsapp(id),

    -- Quem enviou (respons√°vel pela vaga)
    contato_id UUID REFERENCES contatos_grupo(id),
    sender_jid TEXT,
    sender_nome TEXT,

    -- Conte√∫do
    texto TEXT,
    tipo_midia TEXT DEFAULT 'texto',       -- "texto", "imagem", "audio", "documento"
    message_id TEXT UNIQUE,                -- ID do WhatsApp
    timestamp_msg TIMESTAMPTZ,

    -- Processamento
    status TEXT DEFAULT 'pendente',        -- pendente, classificando, descartado_heuristica,
                                           -- classificado_oferta, classificado_nao_oferta,
                                           -- extraindo, extraido, erro
    passou_heuristica BOOLEAN,
    eh_oferta BOOLEAN,
    confianca_classificacao FLOAT,
    motivo_descarte TEXT,
    processado_em TIMESTAMPTZ,
    erro TEXT,

    created_at TIMESTAMPTZ DEFAULT now()
);

-- Vagas extra√≠das dos grupos (staging antes de ir para `vagas`)
CREATE TABLE vagas_grupo (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    mensagem_id UUID REFERENCES mensagens_grupo(id),

    -- Origem (de onde veio a vaga)
    grupo_origem_id UUID REFERENCES grupos_whatsapp(id),
    contato_responsavel_id UUID REFERENCES contatos_grupo(id),

    -- Dados extra√≠dos (raw do LLM)
    hospital_raw TEXT,
    especialidade_raw TEXT,
    setor_raw TEXT,
    periodo_raw TEXT,
    tipo_vaga_raw TEXT,
    forma_pagamento_raw TEXT,
    data DATE,
    hora_inicio TIME,
    hora_fim TIME,
    valor INTEGER,
    observacoes TEXT,

    -- Dados normalizados (ap√≥s match com tabelas existentes)
    hospital_id UUID REFERENCES hospitais(id),
    especialidade_id UUID REFERENCES especialidades(id),
    setor_id UUID REFERENCES setores(id),
    periodo_id UUID REFERENCES periodos(id),
    tipos_vaga_id UUID REFERENCES tipos_vaga(id),
    forma_recebimento_id UUID REFERENCES formas_recebimento(id),

    -- Scores de confian√ßa (0-1)
    confianca_geral FLOAT,                 -- M√©dia ponderada
    confianca_hospital FLOAT,
    confianca_especialidade FLOAT,
    confianca_data FLOAT,
    confianca_valor FLOAT,
    campos_faltando TEXT[],                -- Lista de campos que n√£o conseguiu extrair

    -- Deduplica√ß√£o
    hash_dedup TEXT,                       -- hash(hospital_id+data+periodo_id+especialidade_id)
    eh_duplicada BOOLEAN DEFAULT false,
    duplicada_de UUID REFERENCES vagas_grupo(id),

    -- Rastreamento de m√∫ltiplas fontes
    qtd_fontes INTEGER DEFAULT 1,          -- Quantos grupos postaram esta vaga

    -- Status e importa√ß√£o
    status TEXT DEFAULT 'nova',            -- nova, duplicada, importada, descartada, revisao, erro
    importada_para UUID REFERENCES vagas(id),
    motivo_status TEXT,

    -- Auditoria
    revisada_por TEXT,
    revisada_em TIMESTAMPTZ,
    created_at TIMESTAMPTZ DEFAULT now(),
    updated_at TIMESTAMPTZ DEFAULT now()
);

-- Rastreamento de fontes (uma vaga pode vir de m√∫ltiplos grupos)
CREATE TABLE vagas_grupo_fontes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    vaga_grupo_id UUID REFERENCES vagas_grupo(id) ON DELETE CASCADE,
    mensagem_id UUID REFERENCES mensagens_grupo(id),
    grupo_id UUID REFERENCES grupos_whatsapp(id),
    contato_id UUID REFERENCES contatos_grupo(id),
    ordem INTEGER DEFAULT 1,               -- 1 = primeira fonte, 2 = segunda, etc
    created_at TIMESTAMPTZ DEFAULT now(),

    UNIQUE(vaga_grupo_id, mensagem_id)     -- Evita duplicar mesma mensagem
);

-- Alias de hospitais (para normaliza√ß√£o aprender varia√ß√µes de nome)
CREATE TABLE hospitais_alias (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    hospital_id UUID REFERENCES hospitais(id) ON DELETE CASCADE,
    alias TEXT NOT NULL,                   -- "HSL", "S√£o Luiz ABC", "HSLZ"
    confianca FLOAT DEFAULT 1.0,           -- 1.0 = confirmado manual, <1.0 = inferido
    criado_por TEXT,                       -- "sistema", "importacao", ou user_id
    created_at TIMESTAMPTZ DEFAULT now(),
    UNIQUE(hospital_id, alias)
);

-- Alias de especialidades (mesma l√≥gica)
CREATE TABLE especialidades_alias (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    especialidade_id UUID REFERENCES especialidades(id) ON DELETE CASCADE,
    alias TEXT NOT NULL,                   -- "cardio", "CM", "GO"
    confianca FLOAT DEFAULT 1.0,
    criado_por TEXT,
    created_at TIMESTAMPTZ DEFAULT now(),
    UNIQUE(especialidade_id, alias)
);

-- √çndices para performance
CREATE INDEX idx_mensagens_grupo_status ON mensagens_grupo(status);
CREATE INDEX idx_mensagens_grupo_timestamp ON mensagens_grupo(timestamp_msg);
CREATE INDEX idx_mensagens_grupo_grupo ON mensagens_grupo(grupo_id);
CREATE INDEX idx_vagas_grupo_status ON vagas_grupo(status);
CREATE INDEX idx_vagas_grupo_hash ON vagas_grupo(hash_dedup);
CREATE INDEX idx_vagas_grupo_data ON vagas_grupo(data);
CREATE INDEX idx_vagas_grupo_grupo ON vagas_grupo(grupo_origem_id);
CREATE INDEX idx_vagas_grupo_hospital ON vagas_grupo(hospital_id);
CREATE INDEX idx_hospitais_alias_alias ON hospitais_alias(alias);
CREATE INDEX idx_especialidades_alias_alias ON especialidades_alias(alias);
```

### Fluxo de Importa√ß√£o para Tabela `vagas`

Quando uma vaga √© aprovada para importa√ß√£o:

```sql
-- Exemplo de INSERT na tabela vagas a partir de vagas_grupo
INSERT INTO vagas (
    hospital_id,
    especialidade_id,
    setor_id,
    periodo_id,
    tipos_vaga_id,
    forma_recebimento_id,
    data,
    hora_inicio,
    hora_fim,
    valor,
    observacoes,
    status,
    created_at
)
SELECT
    vg.hospital_id,
    vg.especialidade_id,
    vg.setor_id,
    vg.periodo_id,
    vg.tipos_vaga_id,
    vg.forma_recebimento_id,
    vg.data,
    vg.hora_inicio,
    vg.hora_fim,
    vg.valor,
    CONCAT(
        'Origem: Grupo WhatsApp (', g.nome, '). ',
        'Contato: ', c.nome, ' (', c.telefone, '). ',
        vg.observacoes
    ),
    'aberta',
    now()
FROM vagas_grupo vg
JOIN grupos_whatsapp g ON g.id = vg.grupo_origem_id
JOIN contatos_grupo c ON c.id = vg.contato_responsavel_id
WHERE vg.id = :vaga_grupo_id
  AND vg.hospital_id IS NOT NULL      -- Obrigat√≥rio
  AND vg.especialidade_id IS NOT NULL -- Obrigat√≥rio
RETURNING id;
```

## Estimativa de Custos LLM

| Etapa | Volume/dia | Modelo | Tokens/msg | Custo/dia |
|-------|------------|--------|------------|-----------|
| Classifica√ß√£o | ~600 msgs | Haiku | ~200 | ~$0.15 |
| Extra√ß√£o | ~150 ofertas | Haiku | ~400 | ~$0.06 |
| **Total** | | | | **~$0.20/dia** |

**Nota:** Custo muito baixo porque:
1. Heur√≠stica filtra 70% antes do LLM
2. Haiku √© o modelo mais barato ($0.25/1M tokens input)

## Depend√™ncias

- Webhook Evolution API (j√° implementado)
- Parser de mensagens (j√° identifica grupos)
- Tabelas `hospitais`, `especialidades`, `periodos` (j√° existem)
- Embeddings Voyage AI (para fuzzy match - opcional)
- Redis (para cache de alias)

## Ordem de Execu√ß√£o

```
                           FASE 1: FUNDA√á√ÉO
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  E01 (Modelo de Dados) ‚îÄ‚îÄ‚ñ∫ E02 (Ingest√£o)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                        FASE 2: CLASSIFICA√á√ÉO
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  E03 (Heur√≠stica) ‚îÄ‚îÄ‚ñ∫ E04 (Classifica√ß√£o LLM)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                        FASE 3: EXTRA√á√ÉO
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  E05 (Extra√ß√£o de Dados)                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                        FASE 4: NORMALIZA√á√ÉO
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  E06 (Fuzzy Match) ‚îÄ‚îÄ‚ñ∫ E07 (Cria√ß√£o Hospital Web)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                        FASE 5: PROCESSAMENTO
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  E08 (Deduplica√ß√£o) ‚îÄ‚îÄ‚ñ∫ E09 (Importa√ß√£o Autom√°tica)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                        FASE 6: OPERA√á√ÉO
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  E10 (Interface Slack)                                   ‚îÇ
‚îÇ  E11 (Worker e Orquestra√ß√£o)                             ‚îÇ
‚îÇ  E12 (M√©tricas e Monitoramento)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Crit√©rios de Aceite da Sprint

- [ ] Mensagens de grupo sendo salvas (n√£o mais ignoradas)
- [ ] Heur√≠stica filtrando >60% das mensagens n√£o-ofertas
- [ ] LLM classificando ofertas com >85% precis√£o
- [ ] Extra√ß√£o capturando hospital, data, valor em >80% dos casos
- [ ] Fuzzy match de hospitais funcionando com >75% precis√£o
- [ ] Deduplica√ß√£o identificando vagas repetidas
- [ ] Importa√ß√£o autom√°tica para vagas de alta confian√ßa
- [ ] Rastreamento completo de fontes
- [ ] M√©tricas de pipeline dispon√≠veis (volume, convers√£o, confian√ßa)

## Riscos e Mitiga√ß√µes

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| Volume maior que esperado | M√©dia | M√©dio | Rate limiting no worker, batching |
| Precis√£o baixa de extra√ß√£o | M√©dia | Alto | Prompt engineering iterativo, exemplos |
| Muitos hospitais desconhecidos | Alta | M√©dio | Fila de revis√£o, aprendizado de alias |
| Lat√™ncia do pipeline | Baixa | M√©dio | Workers ass√≠ncronos, n√£o bloqueia webhook |

## M√©tricas de Sucesso

| M√©trica | Meta |
|---------|------|
| Mensagens capturadas/dia | 100% do volume |
| Taxa filtro heur√≠stico | >60% descartadas |
| Precis√£o classifica√ß√£o LLM | >85% |
| Precis√£o extra√ß√£o (campos cr√≠ticos) | >80% |
| Precis√£o fuzzy match hospital | >75% |
| Taxa deduplica√ß√£o | Medir (sem meta inicial) |
| Taxa importa√ß√£o autom√°tica | >50% das vagas v√°lidas |
| Lat√™ncia m√©dia do pipeline | <5 min (n√£o real-time) |

## Arquivos a Criar

```
app/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ grupos/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestor.py           # E01: Salva mensagens
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classificador.py      # E02: Heur√≠stica + LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extrator.py           # E03: Parsing com LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalizador.py       # E04: Fuzzy match
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deduplicador.py       # E05: Hash + janela temporal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ importador.py         # E06: Regras de importa√ß√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ worker.py             # Orquestra o pipeline
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ parser.py                 # Modificar para n√£o ignorar grupos
‚îÇ
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îî‚îÄ‚îÄ slack/
‚îÇ       ‚îî‚îÄ‚îÄ grupos.py             # E06: Tools de gest√£o via Slack
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ routes/
‚îÇ       ‚îî‚îÄ‚îÄ grupos.py             # Endpoints de m√©tricas/admin
‚îÇ
tests/
‚îú‚îÄ‚îÄ grupos/
‚îÇ   ‚îú‚îÄ‚îÄ test_ingestor.py
‚îÇ   ‚îú‚îÄ‚îÄ test_classificador.py
‚îÇ   ‚îú‚îÄ‚îÄ test_extrator.py
‚îÇ   ‚îú‚îÄ‚îÄ test_normalizador.py
‚îÇ   ‚îú‚îÄ‚îÄ test_deduplicador.py
‚îÇ   ‚îî‚îÄ‚îÄ test_importador.py

scripts/
‚îî‚îÄ‚îÄ backfill_grupos.py            # Importar grupos existentes
```

## Timeline Sugerido

| Fase | √âpicos | Estimativa |
|------|--------|------------|
| Fase 1: Funda√ß√£o | E01, E02 | 2 dias |
| Fase 2: Classifica√ß√£o | E03, E04 | 2 dias |
| Fase 3: Extra√ß√£o | E05 | 1.5 dias |
| Fase 4: Normaliza√ß√£o | E06, E07 | 2.5 dias |
| Fase 5: Processamento | E08, E09 | 2 dias |
| Fase 6: Opera√ß√£o | E10, E11, E12 | 4 dias |

**Total estimado:** 14 dias (~3 semanas)

## Notas de Implementa√ß√£o

### Heur√≠stica de Classifica√ß√£o (E02)

Keywords positivas (indica oferta):
- `plant√£o`, `plantao`, `vaga`, `escala`
- `R$`, `reais`, `pago`, `valor`
- Nomes de hospitais conhecidos
- Especialidades m√©dicas
- Datas (dd/mm, dia XX)

Keywords negativas (indica conversa normal):
- `bom dia`, `boa tarde`, `boa noite`
- `obrigado`, `obrigada`, `valeu`
- `?` no final (pergunta)
- Mensagens muito curtas (<10 chars)

### Prompt de Extra√ß√£o (E03)

**IMPORTANTE:** Uma mensagem pode conter M√öLTIPLAS vagas. O prompt retorna um ARRAY.

```
Voc√™ √© um extrator de dados de ofertas de plant√£o m√©dico.
Analise a mensagem abaixo e extraia os dados estruturados.

IMPORTANTE: Uma mensagem pode conter M√öLTIPLAS vagas (ex: lista de escalas).
Retorne um ARRAY de vagas, mesmo que seja apenas uma.

Data de hoje: {data_hoje}

Para CADA VAGA encontrada, extraia:

OBRIGAT√ìRIOS (sem estes a vaga n√£o pode ser importada):
- hospital: nome do hospital/cl√≠nica/UPA
- especialidade: especialidade m√©dica requerida

IMPORTANTES:
- data: data no formato YYYY-MM-DD (se "amanh√£", "segunda", calcule a data real)
- hora_inicio: hor√°rio de in√≠cio HH:MM
- hora_fim: hor√°rio de fim HH:MM
- valor: valor em reais (apenas n√∫mero inteiro, sem centavos)

OPCIONAIS:
- periodo: um de [Diurno, Vespertino, Noturno, Cinderela, Meio per√≠odo (manh√£), Meio per√≠odo (tarde)]
- setor: um de [Pronto atendimento, RPA, Hospital, C. Cir√∫rgico, SADT]
- tipo_vaga: um de [Cobertura, Fixo, Ambulatorial, Mensal]
- forma_pagamento: um de [Pessoa fisica, Pessoa jur√≠dica, CLT, SCP, S√≥cio cotista]
- observacoes: outras informa√ß√µes relevantes (exig√™ncias, benef√≠cios, etc)

REGRAS:
1. Se a data da vaga for ANTERIOR a hoje, marque data_valida: false
2. Se n√£o conseguir identificar hospital OU especialidade, n√£o inclua a vaga
3. Campos compartilhados (ex: mesmo hospital para v√°rias datas) devem ser repetidos em cada vaga

CONFIAN√áA (0 a 1):
- 1.0: Informa√ß√£o expl√≠cita e clara
- 0.7-0.9: Inferida com alta certeza
- 0.4-0.6: Inferida com incerteza
- null: N√£o extra√≠do

Formato de resposta:
{
  "vagas": [
    {
      "dados": {
        "hospital": "Hospital S√£o Luiz ABC",
        "especialidade": "Cl√≠nica M√©dica",
        "data": "2024-12-28",
        "hora_inicio": "19:00",
        "hora_fim": "07:00",
        "valor": 1800,
        "periodo": "Noturno",
        "forma_pagamento": "Pessoa jur√≠dica"
      },
      "confianca": {
        "hospital": 0.95,
        "especialidade": 0.90,
        "data": 1.0,
        "valor": 0.95
      },
      "data_valida": true,
      "campos_faltando": ["setor"]
    }
  ],
  "total_vagas": 1,
  "tem_vaga_passada": false
}

Mensagem do grupo:
{texto}

Contexto adicional:
- Grupo: {nome_grupo}
- Regi√£o: {regiao_grupo}
- Quem postou: {nome_contato}
```

### Exemplos de Mensagens Reais (para calibrar)

**Exemplo 1 - Completa:**
```
üö® VAGA URGENTE üö®
Hospital S√£o Luiz ABC
Cl√≠nica M√©dica
Dia 28/12 - Noturno (19h √†s 7h)
Valor: R$ 1.800,00 PJ
Interessados chamar: (11) 99999-8888
```

**Exemplo 2 - Parcial:**
```
Pessoal, preciso de cardio pro HU Santo Andr√© amanh√£ de manh√£
Pago 2k, quem topa?
```

**Exemplo 3 - Vaga em lote:**
```
Escalas dispon√≠veis S√£o Camilo Pomp√©ia:
- 26/12 Diurno CM
- 27/12 Noturno Pediatria
- 28/12 24h Ortopedia
Valores a combinar. Ligar 11 98765-4321
```

### Fuzzy Match de Hospital (E04)

1. Normalizar texto (lowercase, remover acentos)
2. Buscar match exato em `hospitais_alias`
3. Se n√£o encontrar, calcular similaridade com todos hospitais
4. Se similaridade > 70%, usar match
5. Se < 70%, **criar novo hospital** (ver abaixo)
6. Salvar alias em `hospitais_alias` para aprendizado futuro

### Cria√ß√£o de Hospital Desconhecido (E04)

Quando n√£o encontrar match para um hospital, o sistema deve:

1. **Buscar na web** informa√ß√µes sobre o hospital
   - Usar WebSearch para encontrar dados
   - Buscar: "{nome_hospital} hospital endere√ßo cidade"

2. **Extrair dados** do resultado:
   - Nome completo oficial
   - Endere√ßo (logradouro, n√∫mero, bairro)
   - Cidade e Estado
   - CEP (se dispon√≠vel)

3. **Criar registro** na tabela `hospitais`:
   ```sql
   INSERT INTO hospitais (nome, logradouro, numero, bairro, cidade, estado, cep)
   VALUES (...);
   ```

4. **Criar alias** automaticamente:
   ```sql
   INSERT INTO hospitais_alias (hospital_id, alias, criado_por)
   VALUES (novo_id, 'nome_original_da_mensagem', 'sistema_auto');
   ```

5. **Fallback** se busca web falhar:
   - Criar hospital apenas com nome
   - Marcar `cidade` e `estado` baseado na regi√£o do grupo (se dispon√≠vel)
   - Marcar para revis√£o manual posterior

**Prompt para enriquecimento via web:**
```
Busque informa√ß√µes sobre o hospital/cl√≠nica: "{nome_hospital}"
Regi√£o prov√°vel: {regiao_grupo}

Retorne JSON com:
{
  "nome_oficial": "Nome completo do hospital",
  "logradouro": "Rua/Av...",
  "numero": "123",
  "bairro": "...",
  "cidade": "...",
  "estado": "SP",
  "cep": "00000-000",
  "confianca": 0.85,
  "fonte": "URL de onde veio a informa√ß√£o"
}

Se n√£o encontrar, retorne: {"encontrado": false}
```
