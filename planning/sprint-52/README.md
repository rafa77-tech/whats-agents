# Sprint 52 - Pipeline v3: Extra√ß√£o Inteligente com LLM

**In√≠cio:** 03/02/2026
**Chip em foco:** 5511916175810 (Revoluna)
**Status:** üîÑ Em Andamento

---

## Progresso

| Epic | Status | Descri√ß√£o |
|------|--------|-----------|
| Epic 1: LLM Extrator | ‚úÖ FEITO | `extrator_llm.py` criado e testado |
| Epic 2: Integra√ß√£o Pipeline | ‚úÖ FEITO | Feature flag `PIPELINE_V3_ENABLED` |
| Epic 3: Testes | ‚úÖ FEITO | Bug R$ 202 corrigido |
| Epic 4: Deploy | üìã Pendente | Aguardando ativa√ß√£o em produ√ß√£o |

---

## Objetivo Estrat√©gico

Substituir extra√ß√£o baseada em regex por LLM unificado que classifica E extrai em uma √∫nica chamada. Isso resolve:

1. **Bug dos valores R$ 202** - Regex captura "202" de datas "2026"
2. **Fragilidade do regex** - Padr√µes quebram com varia√ß√µes de formata√ß√£o
3. **Contexto perdido** - Regex n√£o entende contexto sem√¢ntico
4. **Manuten√ß√£o dif√≠cil** - 50+ padr√µes de especialidades para manter

---

## Motiva√ß√£o (Problemas do v2)

### Bug Identificado em Sprint 51

```
Mensagem: "Vaga 19/01/2026, R$ 2.500"
Extra√ß√£o atual: valor = 202 (capturou "202" de "2026")
Resultado: 1.118 vagas com valor R$ 202
```

### Limita√ß√µes Estruturais

| Problema | Impacto |
|----------|---------|
| Regex para valores | Falsos positivos em datas, telefones |
| Regex para especialidades | 50+ padr√µes, f√°cil de quebrar |
| M√∫ltiplas passagens | Contexto perdido entre est√°gios |
| Sem entendimento sem√¢ntico | "5 plant√µes por R$ 2.500" ‚Üí n√£o sabe dividir |

---

## Arquitetura Pipeline v3

### Est√°gios (4 vs 7 do v2)

```
v2: PENDENTE ‚Üí HEURISTICA ‚Üí CLASSIFICACAO ‚Üí EXTRACAO ‚Üí NORMALIZACAO ‚Üí DEDUP ‚Üí IMPORT (7)
v3: PENDENTE ‚Üí DEDUP ‚Üí LLM_UNIFICADO ‚Üí IMPORT (4)
```

### Mudan√ßas Chave

| Est√°gio | v2 | v3 |
|---------|----|----|
| Dedup | Ap√≥s extra√ß√£o | **Antes** (economia de tokens) |
| Heur√≠stica | Regex separado | **Dentro do LLM** |
| Classifica√ß√£o | LLM separado | **Unificado** |
| Extra√ß√£o | Regex | **LLM com JSON** |
| Normaliza√ß√£o | Lookup separado | **LLM retorna normalizado** |

### Prompt Unificado (Classifica√ß√£o + Extra√ß√£o)

```
Voc√™ √© um especialista em classifica√ß√£o de vagas m√©dicas.

Analise a mensagem e retorne JSON:

{
  "eh_vaga": true/false,
  "confianca": 0.0-1.0,
  "motivo_descarte": "string ou null",

  "dados_extraidos": {
    "hospital": "string ou null",
    "especialidade": "string normalizada",
    "valor": n√∫mero ou null,
    "data": "YYYY-MM-DD ou null",
    "periodo": "diurno/noturno/12h/24h",
    "observacoes": "string ou null"
  }
}

REGRAS CR√çTICAS:
- valor √© o pre√ßo POR PLANT√ÉO, n√£o total
- Se "R$ 10.000 por 5 plant√µes", valor = 2000
- N√∫meros em datas (2026, 19/01) N√ÉO s√£o valores
- Especialidade deve ser normalizada (ex: "GO" ‚Üí "Ginecologia e Obstetr√≠cia")
```

---

## √âpicos

### Epic 1: LLM Extrator Unificado (P0) ‚úÖ CONCLU√çDO

**Objetivo:** Substituir extra√ß√£o regex por LLM

**Arquivos criados/modificados:**
- `app/services/grupos/extrator_v2/extrator_llm.py` (NOVO)
- `app/services/grupos/extrator_v2/__init__.py` (exports)
- `app/services/grupos/pipeline_worker.py` (m√©todo `processar_extracao_v3`)

**Tarefas:**
1. [x] Criar `extrator_llm.py` com prompt unificado
2. [x] Definir schema JSON de resposta
3. [x] Implementar convers√£o para VagaAtomica
4. [x] Adicionar cache Redis (24h TTL)
5. [x] Testes com mensagens reais

**Resultados dos Testes:**
```
Caso 1 (Bug R$ 202): ‚úÖ CORRIGIDO - valor=None em vez de 202
Caso 2 (Valor real): ‚úÖ R$ 2.500 extra√≠do corretamente
Caso 3 (N√£o-vaga): ‚úÖ Classifica√ß√£o correta
```

**DoD:**
- [x] Bug R$ 202 eliminado
- [x] Especialidades normalizadas automaticamente
- [x] Cache funcional

---

### Epic 2: Deduplica√ß√£o Antecipada (P1)

**Objetivo:** Mover dedup para ANTES do LLM (economia de tokens)

**L√≥gica:**
```python
# Hash da mensagem (texto normalizado)
hash_msg = hashlib.md5(normalizar(texto)).hexdigest()

# Se j√° processamos mensagem id√™ntica, pular LLM
if ja_processado(hash_msg):
    return resultado_anterior
```

**Tarefas:**
1. [ ] Criar tabela `mensagens_hash` para cache
2. [ ] Implementar normaliza√ß√£o de texto (lowercase, sem emojis, etc)
3. [ ] Mover dedup para antes do LLM no pipeline

**DoD:**
- [ ] Redu√ß√£o de 30%+ em chamadas LLM
- [ ] M√©tricas de economia de tokens

---

### Epic 3: Observabilidade v3 (P1)

**Objetivo:** M√©tricas espec√≠ficas do pipeline v3

**M√©tricas:**
- Tokens consumidos por mensagem
- Taxa de fallback para regex
- Precis√£o de extra√ß√£o (amostragem)
- Lat√™ncia por est√°gio

**Tarefas:**
1. [ ] Adicionar contador de tokens
2. [ ] Dashboard de m√©tricas v3
3. [ ] Alertas de regress√£o

---

### Epic 4: Migra√ß√£o Gradual (P2)

**Objetivo:** Rollout seguro v2 ‚Üí v3

**Estrat√©gia:**
1. Feature flag `PIPELINE_VERSION=v3`
2. A/B test: 10% das mensagens no v3
3. Comparar resultados v2 vs v3
4. Aumentar gradualmente at√© 100%

**Tarefas:**
1. [ ] Implementar feature flag
2. [ ] Logging para compara√ß√£o
3. [ ] Dashboard de A/B test
4. [ ] Runbook de rollback

---

## Estimativas

| Epic | Complexidade | Tempo Estimado |
|------|--------------|----------------|
| Epic 1: LLM Extrator | M√©dia | 2-3 horas |
| Epic 2: Dedup Antecipada | Baixa | 1-2 horas |
| Epic 3: Observabilidade | Baixa | 1-2 horas |
| Epic 4: Migra√ß√£o | M√©dia | 2-3 horas |
| **Total** | | **6-10 horas** |

---

## Riscos e Mitiga√ß√µes

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| Custo de tokens aumenta | M√©dia | M√©dio | Dedup antecipada + cache |
| LLM retorna JSON inv√°lido | Baixa | Alto | Fallback para regex v2 |
| Lat√™ncia aumenta | M√©dia | M√©dio | Batch processing |
| Regress√£o na qualidade | Baixa | Alto | A/B test + monitoramento |

---

## Ordem de Implementa√ß√£o Sugerida

1. **Fase 1 (Hoje):** Epic 1 - LLM Extrator
   - Resolve bug R$ 202 imediatamente
   - Maior impacto, menor risco

2. **Fase 2:** Epic 2 - Dedup Antecipada
   - Otimiza√ß√£o de custo

3. **Fase 3:** Epic 3 + 4 - Observabilidade + Migra√ß√£o
   - Produ√ß√£o segura

---

## Definition of Done (Sprint)

### Obrigat√≥rio (P0)
- [x] LLM extrator funcionando
- [x] Bug R$ 202 corrigido
- [x] Feature flag `PIPELINE_V3_ENABLED`
- [x] Testes passando

### Desej√°vel (P1)
- [ ] Dedup antecipada implementada
- [x] Cache Redis para economia de tokens
- [x] Feature flag para rollback (v2 como fallback)

### Futuro (P2)
- [ ] A/B test completo
- [ ] Dashboard de compara√ß√£o v2 vs v3

---

## Como Ativar

Para ativar o pipeline v3 em produ√ß√£o:

```bash
# Railway - adicionar vari√°vel de ambiente
PIPELINE_V3_ENABLED=true
```

O v3 usa o mesmo fluxo do v2 para persist√™ncia (`_criar_vaga_grupo_v2`), garantindo compatibilidade.
